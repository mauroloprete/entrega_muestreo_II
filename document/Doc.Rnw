\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{ulem}
\usepackage{stackengine}
\usepackage{appendix}
\usepackage{caption}
\usepackage[spanish]{babel}
\usepackage[left=2.10cm,top=2.54cm,right=2.30cm,bottom=2.54cm]{geometry}
\setlength{\parindent}{0pt}
\usepackage[font=small,labelfont=bf]{caption}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage[table]{xcolor}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{multicol}
\usepackage{amsmath}
\spanishdecimal{.}
\usepackage[backend=biber]{biblatex}
\defbibfilter{other}{
  not type=book
}

\addbibresource{biblio/bib.bib}
\setlength{\parindent}{0pt}
\usepackage[font=small,labelfont=bf]{caption}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\renewcommand{\listfigurename}{Lista de Figuras}
\renewcommand{\contentsname}{Lista de Contenidos}
\renewcommand{\figurename}{Figura}
\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
\begin{titlepage}
  \centering
  {\scshape\normalsize Universidad de la República \par}
  {\scshape\normalsize Facultad de Ciencias Economicas y de Administración \par}
  {\scshape\normalsize Licenciatura en Estadística \par}
  \vspace{1cm}
  {\scshape\Large Muestreo II \par}
  \vspace{0.5cm}

  \includegraphics[scale = 0.40]{4711276.png}
  \vfill
  {\scshape\Large Proyecto final \par}
  \vfill
  
  \vspace{1cm}
  {\Large Ignacio Acosta - Valentina Caldiroli - Mauro Loprete \par}
  \vfill
\end{titlepage}
\setkeys{Gin}{width=0.8\textwidth}

<<include = FALSE>>=

if(!require(pacman)) {
  install.packages("pacman")
}

pacman::p_load(
    here,
    dplyr,
    srvyr,
    readxl,
    dplyr,
    forcats,
    tidytable,
    kableExtra,
    magrittr,
    ggplot2,
    tidymodels,
    xgboost,
    PracTools
)

here(
    "data",
    "muestra grupo 4.xlsx"
) %>%
read_excel(
    .
) %>%
mutate.(
    edad_tramo = cut(
        edad,
        breaks = c(0,14,20,25,30,40,50,60,Inf),
        right=FALSE
    )
) %>%
assign(
    "muestra",
    .,
    envir = .GlobalEnv
)

options(kableExtra.latex.load_packages = FALSE)

 knitr::write_bib(
   .packages(),
   here(
     "document",
     "biblio",
     "bib.bib"
   )
 )



# Para poder recuperar el script de los chunk

knitr::purl(
  here::here(
    "document",
    "Doc.Rnw"
  )
)
@

\newpage
\section*{Parte 1 : Estimaciones con ponderadores originales}

Se calculan las estimaciones con los ponderadores originales,
estimaciones de la tasa de desempleo, la proporción de personas pobres e 
ingreso promedio. 
\\

Dada la existencia de no respuesta en la muestra y el tratamiento
realizado, estamos frente a \textbf{una postura deterministica de la no respuesta}. 
\\

A continuación se muestra el código utilizado para realizar las diferentes estimaciones :

<<>>=
muestra %>%
    as_survey_design(
        ids = id_hogar,
        weight = w0,
        strata = estrato
    ) %T>%
    assign(
        "diseño",
        .,
        envir = .GlobalEnv
    ) %>%
    filter(
        R > 0
    ) %>%
    summarize(
        td = survey_ratio(
            desocupado,
            activo,
            deff = TRUE,
            vartype = c("se","cv")
        ),
        pobre = survey_mean(
            pobreza,
            deff = TRUE,
            vartype = c("se","cv")
        ),
        yprom = survey_mean(
            ingreso,
            deff = TRUE,
            vartype = c("se","cv")
        )
    ) %>%
    assign(
      "est_originales",
      .,
      envir = .GlobalEnv
    )
@

\newpage

Los resultados se encuentran en el siguiente cuadro: 

<<echo = FALSE>>=
 est_originales %>%
    pivot_longer.(
        names_to = "v",
        values_to = "value"
    ) %>%
    mutate.(
        tipo = stringr::str_extract(
            v,
            "[a-z]*$"
        ),
        variable = stringr::str_extract(
            v,
            "^[a-z]*"
        ),
        .keep = "unused"
    ) %>%
    mutate.(
        tipo = fct_collapse(
            tipo,
            "estimacion" = c(
                "td",
                "yprom",
                "pobre"
            )
        )
    ) %>%
    mutate.(
        across.(
            where(is.numeric),
            ~ round(
                .x,
                3
            )
        )
    ) %>%
    pivot_wider.(
        names_from = "tipo",
        values_from = "value"
    ) %>%
    relocate.(
      variable,
      estimacion,
      se,
      cv,
      deff
    ) %>%
    set_names(
      c(
        "Variable",
        "Estimación puntual",
        "Error estandar",
        "CV",
        "deff"
      )
    ) %>%
    kbl(
        booktabs = T,
        caption = "Estimaciones poblacionales usando ponderadores originales"
    ) %>%
    kable_styling(
        latex_options = c(
            "striped",
            "hold_position"
        )
    )
@


Con base en el cuadro, se puede ver que los errores estándar son relativamente chicos.

Analizando el incremento de varianza respecto a un diseño simple, haciendo uso del efecto $deff$, puede verse como las mismas son altas debido al diseño en varias etapas de esta encuesta.


\subsection*{Tasa de no respuesta}

Un enfoque determinista de la tasa de no respuesta plantea a la misma como el cociente entre la cantidad de personas que sí respondieron a la pregunta de interés y el total de personas de la muestra.

Es decir, es posible particionar la muestra en los respondentes $r_{u}$ y no respondentes $s-r_{u}$.
\\

\begin{equation*}
    p_{r_{u}} = \frac{n_{r_{u}}}{n_{s}}
\end{equation*}

Para nuestra muestra particular, esta medida viene dada por : 

<<>>=
muestra %>%
    summarize.(
        tr = mean(R)
    ) %>%
    mutate.(
        tnr = 1 - tr
    ) %>%
    assign(
        "tasaRespuesta",
        .,
        envir = .GlobalEnv
    )
@

<<echo = FALSE>>=
tasaRespuesta %>%
    set_names(
        c(
            "Tasa de Respuesta",
            "Tasa de No Respuesta"
        )
    ) %>%
    mutate.(
        across.(
            .fns = ~ round(.x,2)
        )
    ) %>%
    kbl(
        booktabs = T,
        caption = "Tasa de Respuesta"
    ) %>%
    kable_styling(
        latex_options = c(
            "striped",
            "hold_position"
        )
    )
@
En base a este indicador, podemos ver que poco más de la mitad de las personas seleccionadas en la muestra
se pudo recabar información.

\newpage

Por último, podemos ver la tasa de no respuesta poblacional, definida como : 

\begin{equation*}
    \hat{p}_{r_{u}} = \frac{\sum_{r_{u}}{w_{0}}}{\sum_{r_{s}}{w_{0}}} = \frac{\hat{N}_{r_{u}}}{\hat{N}_{s}}
\end{equation*}

<<>>=
muestra %>%
    summarize.(
        tr = sum(R*w0) / sum(w0)
    ) %>%
    assign(
        "tasaRespuestapob",
        .,
        envir = .GlobalEnv
    )
@

<<echo = FALSE>>=
tasaRespuestapob %>%
    mutate.(
        tnr = 1 - tr
    ) %>%
    mutate.(
        across.(
            .fns = ~ round(.x,2)
        )
    ) %>%
    set_names(
        c(
            "Tasa de respuesta poblacional",
            "Tasa de no respuesta poblacional"
        )
    ) %>%
    kbl(
        booktabs = T,
        caption = "Tasa de Respuesta poblacional"
    ) %>%
    kable_styling(
        latex_options = c(
            "striped",
            "hold_position"
        )
    )
@

Considerando 2 cifras significativas en el análisis, la tasa calculada en esta sección coincide con la anterior.
\\

Esta estimación tiene la siguiente interpretación : \textit{ \%54 es el porcentaje de la población que estoy 
cubriendo una vez expandida la muestra}, que para este caso particular, \textbf{es sumamente bajo}.

\newpage

\section*{Parte 2}

\subsection*{Parte a}

A continuación se calcuara la tasa de respuesta asumiendo un patrón del tipo MAR. En el mismo se supone que la tasa de respuesta puede ser expresada como una función de un set de covariables, es decir $\Phi_{i}=\Phi_{i}(\vec{X})$.
\\

Este tipo de estrategia se basa en crear grupos de individuos con comportamiento similar en la no respuesta, a todos los ponderadores considerados dentro del mismo
grupo se le aplicara el mismo ajuste $\Phi_{i}$.
\\

Los diferentes grupos de no respuesta se construirán con base en el departamento y estrato al que pertenecen, para aprovechar al máximo las variables consideradas en el marco.
\\

A exepción de Montevideo, Canelones y San José que presentan comportamientos disímiles entre algunos subsectores, a cada departamento se le imputara la tasa de respuesta de su mismo departamento. 


<<>>=
muestra %>%
    summarize.(
        tr_w_estrato_dpto = weighted.mean(
            R
        ),
        .by = c(
            "estrato",
            "dpto"
        )
    ) %>%
    assign(
        "tr_estrato_dpto",
        .,
        envir = .GlobalEnv
    )

muestra %<>%
    left_join.(
        tr_estrato_dpto,
        by = c(
            "estrato" = "estrato",
            "dpto" = "dpto"
        )
    ) %>%
    mutate.(
        w_nr_post = w0 / tr_w_estrato_dpto
    )


@

<<echo = FALSE,fig.cap= "Tasa de respuesta ponderada por departamento y estrato">>=
tr_estrato_dpto %>%
    mutate.(
        dpto_label = case_when.(
            dpto == 1 ~ "Montevideo",
            dpto == 3 ~ "Canelones",
            dpto == 16 ~ "San José"
        )
    ) %>%
    mutate.(
      estrato_label = case_when.(
          estrato == 1 ~ "Montevideo Bajo",
          estrato == 2 ~ "Montevideo Medio Bajo",
          estrato == 3 ~ "Montevideo medio",
          estrato == 4 ~ "Montevideo medio alto",
          estrato == 5 ~ "Montevideo Alto",
          estrato == 6 ~ "Zona metropolitana",
          estrato == 7 ~ "Interior norte",
          estrato == 8 ~ "Costa Este",
          estrato == 9 ~ "Litoral Norte",
          estrato == 10 ~ "Litoral sur",
          estrato == 11 ~ "Centro Norte",
          estrato == 12 ~ "Centro sur"
      )
    ) %>%
    filter.(
        dpto %in% c(
            1,
            3,
            16
        )
    ) %>%
    ggplot(
        aes(
            x = as.factor(estrato),
            y = tr_w_estrato_dpto,
            color = estrato_label
        )
    ) + 
    geom_segment(
        aes(
            xend = as.factor(estrato),
            y = 0,
            yend = tr_w_estrato_dpto
        ),
        size = 0.9
    ) + 
    geom_point() + 
    scale_y_continuous(
        labels = scales::percent,
        limits = c(0, NA)
    ) + 
    facet_wrap(
        vars(
            dpto_label
        ),
        scales = "free_x"
    ) + 
    labs(
        x = "",
        y = "Tasa de respuesta ponderada",
        color = "Estrato"
    ) + 
    theme_bw() + 
    theme(
        axis.text.x = element_blank(),
        axis.ticks = element_blank(),
        legend.position = "bottom"
    ) + 
    scale_colour_viridis_d(
        option = "inferno"
    )
@


La gráfica ilustra los diferentes comportamientos de la tasa de respuesta en los diferentes departamentos, aunque la mayor diferencia se nota
en San José, con una tasa de respuesta mayor en el Litoral Sur respecto al de la zona metropolitana.
\\

En lo que refiere a Montevideo,puedese puede ver una relación creciente (no monótona debido al estrato medio alto) al estrato referido al 
contexto económico \footnote{Asumiendo que los estratos son los mismos que el de la ECH} para la tasa de respuesta, mientras que para
Canelones no se notan grandes diferencias.
\newpage

Una vez hecho esto, se continuará con el ajuste por no respuesta para los ponderadores originales: 
\\

<<>>=
muestra %>%
    as_survey_design(
        ids = id_hogar,
        weight = w_nr_post,
        strata = estrato
    ) %T>%
    assign(
        "diseño",
        .,
        envir = .GlobalEnv
    ) %>%
    filter(
        R > 0
    ) %>%
    summarize(
        td = survey_ratio(
            desocupado,
            activo,
            deff = TRUE,
            vartype = c("se","cv")
        ),
        pobre = survey_mean(
            pobreza,
            deff = TRUE,
            vartype = c("se","cv")
        ),
        yprom = survey_mean(
            ingreso,
            deff = TRUE,
            vartype = c("se","cv")
        ),
        deffK = deff(
          w_nr_post,
          type = "kish"
        )
    ) %>%
    assign(
      "est_ponderados_nr",
      .,
      envir = .GlobalEnv
    )
@

Resultando así, las estimaciones del punto anterior y considerando además el \textit{Efecto diseño de Kish}.

<<echo = FALSE>>=
est_ponderados_nr %>%
    pivot_longer.(
        - deffK,
        names_to = "v",
        values_to = "value"
    ) %>%
    mutate.(
        tipo = stringr::str_extract(
            v,
            "[a-z]*$"
        ),
        variable = stringr::str_extract(
            v,
            "^[a-z]*"
        ),
        .keep = "unused"
    ) %>%
    mutate.(
        tipo = fct_collapse(
            tipo,
            "estimacion" = c(
                "td",
                "yprom",
                "pobre"
            )
        )
    ) %>%
    mutate.(
        across.(
            where(is.numeric),
            ~ round(
                .x,
                3
            )
        )
    ) %>%
    pivot_wider.(
        names_from = "tipo",
        values_from = "value"
    ) %>%
    relocate.(
      variable,
      estimacion,
      se,
      cv,
      deff,
      deffK
    ) %>%
    set_names(
      c(
        "Variable",
        "Estimación puntual",
        "Error estandar",
        "CV",
        "deff",
        "Efecto diseño de Kish"
      )
    ) %>%
    kbl(
        booktabs = T,
        caption = "Estimaciones poblacionales usando ponderadores por no respuesta"
    ) %>%
    kable_styling(
        latex_options = c(
            "striped",
            "hold_position"
        )
    )
@

Una vez realizado el ajuste, estimaciones de las variables, cálculo de error estándar, coeficiente de variación y efecto diseño, los mismos difirieron un poco con los calculados en el enfoque determinístico.
\\

Algo que puede llamar la atención es como bajó el ingreso promedio, así como todas las estimaciones referidas
a su estadístico.

A lo que refiere al efecto diseño de Kish, podemos ver que se encuentra en un nivel de $1.03$ un aumento 
poco considerable en la variabilidad de los ponderadores, respecto a un diseño autoponderado.

\subsection*{Parte b}

Mediante el uso de modelos de Machine Learning de aprendizaje supervizado, estimaremos el \textit{propensity score}. Se hizo uso del método de \textbf{Gradient boosting}.
\\

Este tipo de modelos es similar al Random Forest, generando diferentes arboles de decisión y promediando sus resultados.

La diferencia con este último es que la secuencia de árboles es dependiente de la realización anterior, ya que en cada
paso se minimiza una función de pérdida (predicciones contra valores observados). 
\\

Este tipo de modelos supera a los del tipo de RF, ya que cada nuevo árbol de clasificación se genera tomando en cuenta 
los errores del paso anterior y no simplemente por azar.
\\

Dado que este tipo de modelos tiende a tener problemas de sobreajuste, debemos de elegir una cantidad de árboles moderada,
en nuestro caso 200.
\\

<<echo = FALSE, fig.caption="Gráfico de dispersión tasa de respuesta por edad y sexo">>=
muestra %>%
    summarize.(
        tr_w = mean(R),
        .by = c(
            "edad",
            "sexo"
        )
    ) %>%
    mutate.(
        sexo = case_when.(
            sexo == 1 ~ "Masculino",
            TRUE ~ "Femenino"
        )
    ) %>%
    ggplot(
        aes(
            x = edad,
            y = tr_w 
        )
    ) + 
    geom_point(
        aes(
            color = sexo
        ),
        size = 2
    ) +
    labs(
        x = "Edad",
        y = "Tasa de respuesta ponderada",
        color = "Sexo"
    ) + 
    theme_bw() + 
    theme(
        legend.position = "bottom"
    ) + 
    scale_colour_viridis_d()
@

Salvo exepciones, puede verse que en edades jovenes y adultas la tasa de respuesta no es diferente según sexo. En edades ancianas, la tasa de respuesta en mujeres tiende a aumentar respecto a la de los hombres,
es por esto que sería bueno incluir estas dos variables en el modelo de clasificación.


<<warning = FALSE>>=
boost_tree(
    trees = 300
) %>%
set_engine(
    "xgboost"
) %>%
set_mode(
    "classification"
) %>%
fit(
    as.factor(R) ~ estrato + sexo + edad + dpto, data = muestra
) %>%
assign(
    "modelo_boost",
    .,
    envir = .GlobalEnv
)
@

\newpage
\subsubsection*{Análisis de ajuste}
<<echo = FALSE>>=
tibble(
    predict(
        modelo_boost,
        muestra, 
        type = "prob"
    ),
    predict(
        modelo_boost,
        muestra
    )
) %>%
rename.(
    pred_boost = .pred_1
) %>%
assign(
    "pred_boost",
    .,
    envir = .GlobalEnv
)

nombres <- c(1,2)

names(nombres) <- c("Predicción","Observados")


conf_mat(
  data = bind_cols(
    select(muestra, R),
    select(pred_boost,.pred_class)
  ),
  truth = R, 
  estimate = .pred_class
) %$%
table %>%
kbl(
    booktabs = TRUE,
    caption = "Matriz de confusión"
) %>%
add_header_above(
    nombres
) %>%
kable_styling(
        latex_options = c(
            "striped",
            "hold_position"
        )
    )
@

A lo que refiere a la sensibilidad del modelo podemos ver que es de $70 \%$, mientras que la especificidad es de
un casi $62 \%$ y un error total de $31 \%$ . Se calculan las propensiones individuales y ajustamos los ponderadores
por no respuesta:
\\



<<>>=

muestra %<>%
    bind_cols.(
        pred_boost
    ) %>%
    mutate.(
        w_nr_boost = (w0*R)/(pred_boost)
    )
@

<<>>=
muestra %>%
    as_survey_design(
        ids = id_hogar,
        weight = w_nr_boost,
        strata = estrato
    ) %T>%
    assign(
        "diseño_boost",
        .,
        envir = .GlobalEnv
    ) %>%
    filter(
        R > 0
    ) %>%
    summarize(
        td = survey_ratio(
            desocupado,
            activo,
            deff = TRUE,
            vartype = c("se","cv")
        ),
        pobre = survey_mean(
            pobreza,
            deff = TRUE,
            vartype = c("se","cv")
        ),
        yprom = survey_mean(
            ingreso,
            deff = TRUE,
            vartype = c("se","cv")
        ),
        deffK = deff(
          w_nr_boost,
          type = "kish"
        )
    ) %>%
    assign(
      "est_ponderados_nr_boost",
      .,
      envir = .GlobalEnv
    )
@

<<echo = FALSE>>=
est_ponderados_nr_boost %>%
    pivot_longer.(
        - deffK,
        names_to = "v",
        values_to = "value"
    ) %>%
    mutate.(
        tipo = stringr::str_extract(
            v,
            "[a-z]*$"
        ),
        variable = stringr::str_extract(
            v,
            "^[a-z]*"
        ),
        .keep = "unused"
    ) %>%
    mutate.(
        tipo = fct_collapse(
            tipo,
            "estimacion" = c(
                "td",
                "yprom",
                "pobre"
            )
        )
    ) %>%
    mutate.(
        across.(
            where(is.numeric),
            ~ round(
                .x,
                3
            )
        )
    ) %>%
    pivot_wider.(
        names_from = "tipo",
        values_from = "value"
    ) %>%
    relocate.(
      variable,
      estimacion,
      se,
      cv,
      deff,
      deffK
    ) %>%
    set_names(
      c(
        "Variable",
        "Estimación puntual",
        "Error estandar",
        "CV",
        "deff",
        "Efecto diseño de Kish"
      )
    ) %>%
    kbl(
        booktabs = T,
        caption = "Estimaciones poblacionales usando ponderadores por no respuesta utilizando Boosting"
    ) %>%
    kable_styling(
        latex_options = c(
            "striped",
            "hold_position"
        )
    )
@


Una vez realizadas las estimaciones, se puede ver que las estimaciones difieren poco.
Se nota a su vez un leve aumento en los errores estándar y coeficientes de variación, sin embargo
se puede notar un aumento en el efecto diseño, así como también en el efecto diseño de Kish.
\\

Este último, si bien es mas alto que el anterior basándonos en la regla empírica, no es algo para preocuparse por el momento.

Por último, veremos un gráfico de dispersión de los ponderadores originales,
respecto a los recién ajustados.
\\

<<echo = FALSE,fig.cap= "Gráfica de dispersión de ponderadores originales vs propensiones con Boosting">>=
muestra %>%
    filter.(
        R > 0
    ) %>%
    ggplot(
        aes(
            x = w0,
            y = w_nr_boost
        )
    ) + 
    geom_point(
        size = 2
    ) +
    labs(
        x = "Ponderadores originales",
        y = "Ponderadores NR con boosting"
    ) + 
    theme_bw()
@

En este gráfico puede verse como se aumentaron los ponderadores, algunos de ellos de forma considerable. Si bien esto puede sonar alarmante los 
encuestados respondentes tienen que brindar información sobre los que no respondieron. Al tener tasas de respuesta bajas, la variación de los ponderadores,
tiene que reflejar esa situación. 
\\

Algo a considerar, es que la estimación de la población obtenida con este nuevo sistema de ponderadores ($3.415.329$) siendo la original de ($3.518.412$) 
son similares entre sí, algo que no ocurría utilizando la estrategia de la parte 2, esta estimación crecia a casí el doble $6.582.193$.

\subsection*{Parte c}

Con el mismo modelo de la parte anterior se ajustarán las no respuesta mediante propensiones estratificadas. Para ello se dividirán las propensiones en sus quintiles y luego a cada grupo se le asigna la propensión mediana. 
\\

Primero realizaremos un histograma de estas propensiones : 

<<echo = FALSE,fig.cap = "Histograma de propensiones del método Boosting">>=
muestra %>%
    ggplot(
        aes(
            x = pred_boost
        )
    ) + 
    geom_histogram(
        bins = nrow(muestra) ^ 0.5,
        fill = "blue",
        alpha = 0.6
    ) + 
    theme_bw()
@

Podemos ver una distribución simétrica, centrada en valores poco mas grandes que 
$1/2$ aproximándose al valor de la tasa de respuesta. 
\\

A continuación calcularemos las propensiones estratificadas utilizando los quintiles de la distribución
para agrupar y el estadístico utilizado para resumir el score será la mediana: 
\newpage

<<>>=

muestra %<>%
    mutate.(
        boost_class = cut(
            pred_boost,
            breaks = quantile(
                pred_boost,
                probs = seq(0,1,1/5)
            ),
            include.lowest = TRUE
        )
    ) %>%
    mutate.(
        ajuste_boost_clases = 1/median(pred_boost),
        .by = boost_class
    ) %>%
    mutate.(
        w_nr_boost_clases = R * w0 * ajuste_boost_clases
    )

@

<<>>=
muestra %>%
    as_survey_design(
        ids = id_hogar,
        weight = w_nr_boost_clases,
        strata = estrato
    ) %T>%
    assign(
        "diseño_nr_boost_clases",
        .,
        envir = .GlobalEnv
    ) %>%
    filter(
        R > 0
    ) %>%
    summarize(
        td = survey_ratio(
            desocupado,
            activo,
            deff = TRUE,
            vartype = c("se","cv")
        ),
        pobre = survey_mean(
            pobreza,
            deff = TRUE,
            vartype = c("se","cv")
        ),
        yprom = survey_mean(
            ingreso,
            deff = TRUE,
            vartype = c("se","cv")
        ),
        deffK = deff(
          w_nr_boost_clases,
          type = "kish"
        )
    ) %>%
    assign(
      "est_ponderados_nr_clases",
      .,
      envir = .GlobalEnv
    )
@

<<echo = FALSE>>=
est_ponderados_nr_boost %>%
    pivot_longer.(
        - deffK,
        names_to = "v",
        values_to = "value"
    ) %>%
    mutate.(
        tipo = stringr::str_extract(
            v,
            "[a-z]*$"
        ),
        variable = stringr::str_extract(
            v,
            "^[a-z]*"
        ),
        .keep = "unused"
    ) %>%
    mutate.(
        tipo = fct_collapse(
            tipo,
            "estimacion" = c(
                "td",
                "yprom",
                "pobre"
            )
        )
    ) %>%
    mutate.(
        across.(
            where(is.numeric),
            ~ round(
                .x,
                3
            )
        )
    ) %>%
    pivot_wider.(
        names_from = "tipo",
        values_from = "value"
    ) %>%
    relocate.(
      variable,
      estimacion,
      se,
      cv,
      deff,
      deffK
    ) %>%
    set_names(
      c(
        "Variable",
        "Estimación puntual",
        "Error estandar",
        "CV",
        "deff",
        "Efecto diseño de Kish"
      )
    ) %>%
    kbl(
        booktabs = T,
        caption = "Estimaciones poblacionales usando ponderadores por no respuesta utilizando las propensiones del punto anterior por clases"
    ) %>%
    kable_styling(
        latex_options = c(
            "striped",
            "hold_position"
        )
    )
@

\newpage

\section*{Parte 3}

Una vez realizado el ajuste por no respuesta, vamos a calibrar estos ponderadores en base 
conteos poblacionales por departamento, sexo y edad. Primero construiremos los totales marginales: 

<<>>=
read_excel(
    here(
        "data",
        "dpto.xlsx"
    )
) %>%
rename.(
    personas_dpto = personas 
) %>%
pull.(
    "personas_dpto"
) %>%
unique() %>%
assign(
    "total_dpto",
    .,
    envir = .GlobalEnv
)

edad_sexo <- read_excel(
    here(
        "data",
        "sexo_edad.xlsx"
    )
)

edad_sexo  %>%
    mutate.(
        total = hombres + mujeres,
        .keep = "unused"
    ) %>%
    mutate.(
        edad_tramo = cut(
            edad,
            breaks = c(0,14,20,25,30,40,50,60,Inf),
            right=FALSE
        )
    ) %>%
    summarize.(
        total = sum(total),
        .by = "edad_tramo"
    ) %>% 
    rename.(
        total_edad = total
    ) %>%
    pull.(
        "total_edad"
    ) %>%
    unique() %>%
    assign(
        "total_edad",
        .,
        envir = .GlobalEnv
    )

edad_sexo  %>%
    summarize.(
        hombres = sum(hombres),
        mujeres = sum(mujeres)
    ) %>%
    pivot_longer.(
        names_to = "sexo",
        values_to = "valor"
    ) %>%
    rename.(
        total_sexo = valor
    ) %>%
    mutate.(
        sexo = ifelse.(
            sexo == "hombres",
            1,
            2
        )
    ) %>%
    pull.(
        "total_sexo"
    ) %>%
    unique() %>%
    assign(
        "total_sexo",
         .,
        envir = .GlobalEnv
    )



conteos <- c(
    sum(muestra$w0),
    total_dpto[-1],
    total_edad[-1],
    total_sexo[-1]
)

@

Ahora construiremos los nuevos ponderadores calibrados usando el método de Raking o post-estratificación incompleta, 
recortamos los mismos y aumentamos el tamaño de iteraciones por defecto.
\\

Con los limites fijados los ponderadores pueden variar hasta un $30\%$ de su valor obtenido con las propensiones estratificadas del boosting,es decir, al argumento bounds le fijamos $-1.3$ y $1.3$

<<>>=
survey::calibrate(
    design = diseño_nr_boost_clases,
    formula = ~ as.factor(dpto) + edad_tramo + as.factor(sexo),
    population = conteos,
    calfun = "raking",
    bounds = c(
      -1.3,
      1.3
    ),
    maxit = 100,
    bounds.const = FALSE
) %>%
assign(
    "w_nr_calibrados",
    .,
    envir = .GlobalEnv
)

muestra %<>%
    mutate.(
        w_nr_boost_clases_calibrados = weights(
            w_nr_calibrados
        )
    )

@

Si realizamos un diagrama de dispersión de los ponderadores calibrados y los obtenidos en el punto anterior,
podemos ver su cambio. Si al utilizar trimming en el raking, los totales poblacionales de variables auxiliares no se cumplen de manera exacta para cada grupo, aunque sigue estimando sin error el total poblacional fijado con los ponderadores originales.

<<echo = FALSE,message=FALSE,warning=FALSE,fig.cap= "Gráfico de dispersión de ponderadores por clases vs calibrados">>=
muestra %>%
  filter.(
    R > 0
  ) %>%
ggplot(
    aes(
        x = w_nr_boost_clases,
        y = w_nr_boost_clases_calibrados
    )
) + 
geom_point() + 
geom_smooth() +
theme(
  aspect.ratio = 1
) + 
theme_bw()

@


Antes de culminar esta etapa, podemos ver que el efecto diseño de Kish aumento levemente a \Sexpr{muestra %>% filter.(R>0) %>% summarize.(deffK(w_nr_boost_clases_calibrados)) %>% pull.() %>% round(3)}. 

\newpage

\section*{Parte 4}

una vez realizado el ajuste por no respuesta y calibrando con las variables poblacionales podemos realizar las estimaciones referidas a la tasa de desempleo, la proporción de personas pobres y el ingreso promedio, para personas empleadas mayores a 25 años.

<<>>=

library(survey)

muestra %<>%
  mutate.(
    desocupado = replace_na.(
      desocupado,
      0
    ),
    activo = replace_na.(
      activo,
      0
    )
  )


disenio_final <- as_survey_design(
  muestra,
  ids = id_hogar,
  weight = w_nr_boost_clases_calibrados,
  strata = estrato
)

disenio_final_rep <- survey::as.svrepdesign(
  disenio_final,
  type = "subbootstrap",
  replicates = 500
)

@


\subsection*{Método del útlimo conglomerado}


<<>>=
svyby(
  formula = ~ desocupado,
  by = ~ dpto,
  FUN = svyratio,
  design = disenio_final,
  denominator = ~ activo,
  vartype = c("ci","se","cv")
) %>% 
tibble() %>% 
set_names(
  c(
    "Dpto",
    "Est.",
    "SE",
    "Inter.Inf",
    "Inter.Sup",
    "CV"
  )
) %>% 
mutate.(
  across.(
    -Dpto,
    .fns = ~ round(.x,3)
  )
) %>% 
kbl(
  booktabs = TRUE,
  caption = "Estimación de la tasa de desempleo usando el último conglomerado por Departamento"
) %>% 
kable_styling(
    latex_options = c(
        "striped",
        "hold_position"
    )
)


svyby(
  formula = ~ pobreza,
  by = ~ dpto,
  FUN = svymean,
  na.rm = TRUE,
  design = disenio_final,
  vartype = c("ci","se","cv")
) %>% 
tibble() %>% 
set_names(
  c(
    "Dpto",
    "Est.",
    "SE",
    "Inter.Inf",
    "Inter.Sup",
    "CV"
  )
) %>% 
mutate.(
  across.(
    -Dpto,
    .fns = ~ round(.x,3)
  )
) %>% 
kbl(
  booktabs = TRUE,
  caption = "Estimación de la tasa de pobreza usando el último conglomerado por Departamento"
) %>% 
kable_styling(
    latex_options = c(
        "striped",
        "hold_position"
    )
)

muestra %>% 
  filter.(
    edad >= 25,
    ocupado == 1
  ) %>% 
as_survey_design(
  .,
  ids = id_hogar,
  weight = w_nr_boost_clases_calibrados,
  strata = estrato
) %>%
  assign(
    "disenio_final_aux",
    .,
    envir = .GlobalEnv
  )

svyby(
  formula = ~ ingreso,
  by = ~ dpto,
  FUN = svymean,
  na.rm = TRUE,
  design = disenio_final_aux,
  vartype = c("ci","se","cv")
) %>% 
tibble() %>% 
set_names(
  c(
    "Dpto",
    "Est.",
    "SE",
    "Inter.Inf",
    "Inter.Sup",
    "CV"
  )
) %>% 
mutate.(
  across.(
    -Dpto,
    .fns = ~ round(.x,3)
  )
) %>% 
kbl(
  booktabs = TRUE,
  caption = "Estimación del ingreso promedio usando método del último conglomerado por Departamento"
) %>% 
kable_styling(
    latex_options = c(
        "striped",
        "hold_position"
    )
)
@

\newpage

\subsection*{Usando boostrap Rao-Wu}

<<>>=
svyby(
  formula = ~ desocupado,
  by = ~ dpto,
  FUN = svyratio,
  design = disenio_final_rep,
  denominator = ~ activo,
  vartype = c("ci","se","cv")
) %>% 
tibble() %>% 
set_names(
  c(
    "Dpto",
    "Est.",
    "SE",
    "Inter.Inf",
    "Inter.Sup",
    "CV"
  )
) %>% 
mutate.(
  across.(
    -Dpto,
    .fns = ~ round(.x,3)
  )
) %>% 
kbl(
  booktabs = TRUE,
  caption = "Estimación de la tasa de desempleo usando Boostrap Rao-Wu por Departamento"
) %>% 
kable_styling(
    latex_options = c(
        "striped",
        "hold_position"
    )
)


svyby(
  formula = ~ pobreza,
  by = ~ dpto,
  FUN = svymean,
  na.rm = TRUE,
  design = disenio_final_rep,
  vartype = c("ci","se","cv")
) %>% 
tibble() %>% 
set_names(
  c(
    "Dpto",
    "Est.",
    "SE",
    "Inter.Inf",
    "Inter.Sup",
    "CV"
  )
) %>% 
mutate.(
  across.(
    -Dpto,
    .fns = ~ round(.x,3)
  )
) %>% 
kbl(
  booktabs = TRUE,
  caption = "Estimación de la tasa de pobreza usando Boostrap Rao-Wu por Departamento"
) %>% 
kable_styling(
    latex_options = c(
        "striped",
        "hold_position"
    )
)

muestra %>% 
  filter.(
    edad >= 25,
    ocupado == 1
  ) %>% 
as_survey_design(
  .,
  ids = id_hogar,
  weight = w_nr_boost_clases_calibrados,
  strata = estrato
) %>%
  assign(
    "disenio_final_aux",
    .,
    envir = .GlobalEnv
  )

disenio_final_rep_aux <- survey::as.svrepdesign(
  disenio_final_aux,
  type = "subbootstrap",
  replicates = 500
)


svyby(
  formula = ~ ingreso,
  by = ~ dpto,
  FUN = svymean,
  na.rm = TRUE,
  design = disenio_final_rep_aux,
  vartype = c("ci","se","cv")
) %>% 
tibble() %>% 
set_names(
  c(
    "Dpto",
    "Est.",
    "SE",
    "Inter.Inf",
    "Inter.Sup",
    "CV"
  )
) %>% 
mutate.(
  across.(
    -Dpto,
    .fns = ~ round(.x,3)
  )
) %>% 
kbl(
  booktabs = TRUE,
  caption = "Estimación del ingreso promedio usando Boostrap Rao-Wu por Departamento"
) %>% 
kable_styling(
    latex_options = c(
        "striped",
        "hold_position"
    )
)

@



\newpage

\section*{Referencias}
\nocite{*}
\printbibliography[title={Libros consultados},type=book]
\printbibliography[title={Paquetes de R},filter=other]

\end{document}
